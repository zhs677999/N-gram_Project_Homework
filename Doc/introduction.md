# Ngram 语言模型项目介绍

## 1. 项目概述

该项目是一个基于 N-gram 语言模型的中文文本生成系统，使用 Qt 框架构建了图形用户界面，能够基于用户输入的提示词自动生成连贯的中文文本。系统采用多层 N-gram 模型（2-gram、3-gram、5-gram、10-gram）实现智能文本预测，支持多种生成策略。

## 2. 整体架构

### 2.1 系统层次结构

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   图形用户界面层   │     │   核心逻辑层     │     │   数据处理层     │
│   ChatWindow    │────▶│   Generate.cpp  │────▶│   read.cpp      │
│   (Qt Widgets)  │     │   (文本生成)      │     │   (N-gram处理)   │
└─────────────────┘     └─────────────────┘     └─────────────────┘
         ▲                     ▲                     ▲
         │                     │                     │
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   模型数据文件   │     │   头文件声明     │     │   原始训练数据   │
│   Model/        │     │   Inc/          │     │   Data/         │
└─────────────────┘     └─────────────────┘     └─────────────────┘
```

### 2.2 主要组件

- **用户界面组件**: ChatWindow 提供了友好的聊天式交互界面，支持用户输入和模型输出展示
- **文本生成引擎**: Generate 模块负责使用 N-gram 模型生成文本
- **N-gram 处理模块**: read 模块处理 UTF-8 字符串，构建和管理 N-gram 计数
- **训练数据**: Data 文件夹包含 497 篇中小学记叙文作为训练语料
- **模型文件**: Model 文件夹存储预训练的 N-gram 模型数据

## 3. 核心功能实现

### 3.1 N-gram 模型构建

```cpp
NgramCounts build_ngram_counts(const std::filesystem::path& dir, int n);
PrefixIndex build_prefix_index(const NgramCounts& ngrams, int n);
```

系统从 Data 目录中的 497 个文本文件构建 N-gram 模型：
- 遍历所有文本文件
- 按 UTF-8 字符处理中文文本
- 生成 n-gram 序列（支持 n=2,3,5,10）
- 统计每个 n-gram 的出现频率
- 构建前缀索引用于快速查找

### 3.2 多模型降级策略

系统同时支持 2-gram、3-gram、5-gram、10-gram 四种模型，采用智能降级策略：
- 优先尝试 10-gram 模型（最准确）
- 如果匹配失败，依次降级为 5-gram、3-gram、2-gram
- 保证在任何输入下都能生成合理的文本

### 3.3 文本生成算法

```cpp
void Generate(const std::string& prompt, std::string& output, int n);
std::string generate_text(const std::string& user_input, int max_length, int n_required);
```

生成文本的核心流程：
1. 初始化 N-gram 模型（第一次调用时执行）
2. 加载或重新生成训练数据
3. 使用加权随机选择算法基于前缀预测下一个字符
4. 持续生成字符直到达到最大长度或足够的句子结束符
5. 返回生成的文本

## 4. 关键技术点

### 4.1 UTF-8 字符处理

考虑到中文文本的复杂性，系统使用自定义函数正确处理 UTF-8 编码：
- `utf8_substr`: 按字符而不是字节截取字符串
- `utf8_length`: 计算 UTF-8 字符串的真实字符数量
- `last_utf8_chars`: 获取字符串最后几个字符作为前缀

### 4.2 训练数据管理

- 支持从原始文本重新生成模型
- 已保存的模型文件存放在 Model 目录
- 当模型文件不存在时，会自动从 Data 目录生成

### 4.3 图形用户界面

使用 Qt 框架构建了现代化的聊天界面：
- 支持聊天气泡显示
- 可通过下拉框选择 N 值
- 提供完整的交互体验

## 5. 工作流程

### 5.1 模型初始化流程

```
启动应用程序 → 第一次调用 Generate() → 检查 Model 文件 → 不存在则生成 → 加载到内存
```

### 5.2 文本生成流程

```
用户输入提示 → 检查输入长度 → 获取最后 n-1 个字符作为前缀 → 查找可能的后续字符 → 加权随机选择 → 持续生成 → 返回结果
```

## 6. 项目结构

```
NgramCode/          # 项目根目录
├── Data/           # 训练数据（497篇记叙文）
├── Doc/            # 文档（包括本文档）
├── Inc/            # 头文件
├── Model/          # 预训练模型
├── Src/            # 源代码
└── NgramChat.pro   # Qt 项目文件
```

## 7. 扩展和改进建议

- 增加更多的训练数据类型（除记叙文外的其他文体）
- 实现模型的增量训练
- 添加模型参数调优功能
- 增加对更复杂语法结构的支持
- 优化模型加载和查询速度
- 添加用户自定义语料库功能
